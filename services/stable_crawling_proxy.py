"""
ì•ˆì •ì ì¸ í¬ë¡¤ë§ í”„ë¡ì‹œ - BigKindsCrawlerì˜ ì•ˆì •ì„± í–¥ìƒ
ì›ë³¸ ì½”ë“œ ìˆ˜ì • ì—†ì´ í”„ë¡ì‹œ íŒ¨í„´ìœ¼ë¡œ ì•ˆì •ì„± ë³´ê°•
"""

import os
import sys
import json
import time
import random
from pathlib import Path
from typing import Dict, List, Optional
from datetime import datetime
import logging

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì •
current_dir = Path(__file__).parent
project_root = current_dir.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from services.crawling_bigkinds import BigKindsCrawler

logger = logging.getLogger(__name__)

class StableBigKindsCrawler:
    """BigKindsCrawlerì˜ ì•ˆì •ì„± í–¥ìƒ í”„ë¡ì‹œ"""
    
    def __init__(self, data_dir: str = "data2", headless: bool = True, issues_per_category: int = 10):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(exist_ok=True)
        self.headless = headless
        self.issues_per_category = issues_per_category
        
        # ì¬ì‹œë„ ì„¤ì •
        self.max_retries = 3
        self.retry_delay = 5  # ì´ˆ
        
        logger.info("âœ… ì•ˆì •ì ì¸ í¬ë¡¤ë§ í”„ë¡ì‹œ ì´ˆê¸°í™”")
    
    def crawl_all_categories_with_retry(self) -> Dict:
        """ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ì•ˆì •ì ì¸ í¬ë¡¤ë§"""
        
        for attempt in range(1, self.max_retries + 1):
            logger.info(f"ğŸ”„ í¬ë¡¤ë§ ì‹œë„ {attempt}/{self.max_retries}")
            
            try:
                # ê° ì‹œë„ë§ˆë‹¤ ìƒˆë¡œìš´ í¬ë¡¤ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
                crawler = self._create_enhanced_crawler()
                
                # í¬ë¡¤ë§ ì‹¤í–‰
                result = crawler.crawl_all_categories()
                
                # ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ë©´ ê²°ê³¼ ë°˜í™˜
                if result.get('total_issues', 0) > 0:
                    logger.info(f"âœ… í¬ë¡¤ë§ ì„±ê³µ (ì‹œë„ {attempt}): {result['total_issues']}ê°œ ì´ìŠˆ")
                    return result
                else:
                    logger.warning(f"âš ï¸ í¬ë¡¤ë§ ì™„ë£Œë˜ì—ˆì§€ë§Œ ì´ìŠˆê°€ ì—†ìŒ (ì‹œë„ {attempt})")
                    
            except Exception as e:
                logger.error(f"âŒ í¬ë¡¤ë§ ì‹¤íŒ¨ (ì‹œë„ {attempt}): {e}")
                
                # ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë©´ ëŒ€ê¸° í›„ ì¬ì‹œë„
                if attempt < self.max_retries:
                    delay = self.retry_delay * attempt  # ì§€ìˆ˜ì  ë°±ì˜¤í”„
                    logger.info(f"â³ {delay}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                    time.sleep(delay)
                else:
                    logger.error(f"âŒ ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨. ìµœì¢… ì‹¤íŒ¨ ì²˜ë¦¬")
                    return self._create_failed_result(str(e))
        
        return self._create_failed_result("ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨")
    
    def _create_enhanced_crawler(self) -> BigKindsCrawler:
        """í–¥ìƒëœ ì„¤ì •ì˜ í¬ë¡¤ëŸ¬ ìƒì„±"""
        
        # ê¸°ì¡´ BigKindsCrawler í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ì•„ ì„¤ì • ê°•í™”
        class EnhancedBigKindsCrawler(BigKindsCrawler):
            def _setup_driver(self):
                """Chrome ë“œë¼ì´ë²„ ì„¤ì • - ì•ˆì •ì„± ê°•í™” ë²„ì „"""
                from selenium import webdriver
                from selenium.webdriver.support.ui import WebDriverWait
                
                options = webdriver.ChromeOptions()
                
                # ê¸°ë³¸ í—¤ë“œë¦¬ìŠ¤ ì„¤ì •
                if self.headless:
                    options.add_argument("--headless")
                    options.add_argument("--no-sandbox")
                    options.add_argument("--disable-dev-shm-usage")
                else:
                    options.add_argument("--start-maximized")
                
                # í–¥ìƒëœ ì•ˆì •ì„± ì„¤ì •
                options.add_argument("--disable-blink-features=AutomationControlled")
                options.add_experimental_option("excludeSwitches", ["enable-automation"])
                options.add_experimental_option('useAutomationExtension', False)
                
                # ì¶”ê°€ ì•ˆì •ì„± ì„¤ì •
                options.add_argument("--disable-web-security")
                options.add_argument("--allow-running-insecure-content")
                options.add_argument("--disable-features=VizDisplayCompositor")
                
                # ë¦¬ì†ŒìŠ¤ ìµœì í™”
                options.add_argument("--disable-extensions")
                options.add_argument("--disable-plugins")
                options.add_argument("--disable-images")  # ì´ë¯¸ì§€ ë¡œë”© ë¹„í™œì„±í™”ë¡œ ì†ë„ í–¥ìƒ
                options.add_argument("--disable-javascript")  # JS ë¹„í™œì„±í™” (í•„ìš”ì‹œ)
                
                # ë©”ëª¨ë¦¬ ìµœì í™”
                options.add_argument("--memory-pressure-off")
                options.add_argument("--max_old_space_size=4096")
                
                # ë¡œê·¸ ë ˆë²¨ ì¡°ì • (ì—ëŸ¬ ë©”ì‹œì§€ ì¤„ì´ê¸°)
                options.add_argument("--log-level=3")
                options.add_experimental_option('excludeSwitches', ['enable-logging'])
                options.add_experimental_option('useAutomationExtension', False)
                
                # User-Agent ì„¤ì • (íƒì§€ ë°©ì§€)
                options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36")
                
                self.driver = webdriver.Chrome(options=options)
                
                # webdriver ì†ì„± ìˆ¨ê¸°ê¸°
                self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
                
                # ëŒ€ê¸° ì‹œê°„ ì¦ê°€ (ê¸°ì¡´ 15ì´ˆ â†’ 30ì´ˆ)
                self.wait = WebDriverWait(self.driver, 30)
                
                print("âœ… í–¥ìƒëœ Chrome ë“œë¼ì´ë²„ ì„¤ì • ì™„ë£Œ")
            
            def _navigate_to_bigkinds(self):
                """BigKinds ì‚¬ì´íŠ¸ ì ‘ì† - ì•ˆì •ì„± ê°•í™”"""
                print("ğŸŒ BigKinds ì‚¬ì´íŠ¸ ì ‘ì† ì¤‘... (ì•ˆì •ì„± ê°•í™”)")
                
                try:
                    self.driver.get("https://www.bigkinds.or.kr/")
                    
                    # í˜ì´ì§€ ë¡œë”© ì™„ë£Œê¹Œì§€ ì¶©ë¶„íˆ ëŒ€ê¸°
                    time.sleep(5)  # ê¸°ì¡´ 3ì´ˆ â†’ 5ì´ˆ
                    
                    # í˜ì´ì§€ ë¡œë”© í™•ì¸
                    self.driver.execute_script("return document.readyState") == "complete"
                    
                    # íŒì—… ë‹«ê¸° ì‹œë„ (ì—¬ëŸ¬ ì„ íƒìë¡œ)
                    popup_selectors = [
                        ".popup-close-btn",
                        ".modal-close",
                        ".close-btn",
                        "[data-dismiss='modal']"
                    ]
                    
                    for selector in popup_selectors:
                        try:
                            popup = self.driver.find_element(By.CSS_SELECTOR, selector)
                            popup.click()
                            time.sleep(1)
                        except:
                            continue
                    
                    print("âœ… BigKinds ì‚¬ì´íŠ¸ ì ‘ì† ì™„ë£Œ (ì•ˆì •ì„± ê°•í™”)")
                    return True
                    
                except Exception as e:
                    print(f"âŒ ì‚¬ì´íŠ¸ ì ‘ì† ì‹¤íŒ¨: {str(e)}")
                    return False
            
            def _crawl_issues_in_category(self, category: str, max_issues: int) -> List[Dict]:
                """ì¹´í…Œê³ ë¦¬ ë‚´ ì´ìŠˆë“¤ í¬ë¡¤ë§ - ì•ˆì •ì„± ê°•í™”"""
                issues = []
                failed_count = 0
                max_failures = 3  # ì—°ì† ì‹¤íŒ¨ í—ˆìš© íšŸìˆ˜
                
                for i in range(1, max_issues + 1):
                    print(f"  ğŸ“° [{i}/{max_issues}] ì´ìŠˆ ì²˜ë¦¬ ì¤‘... (ì‹¤íŒ¨: {failed_count})")
                    
                    try:
                        # 3ë²ˆì§¸ ì´ìŠˆë¶€í„°ëŠ” ìŠ¬ë¼ì´ë“œ ë„˜ê¸°ê¸° í•„ìš”
                        if i >= 3:
                            self._navigate_slides(i)
                        
                        # ì´ìŠˆ ë°ì´í„° ì¶”ì¶œ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
                        issue_data = self._extract_issue_data_with_retry(i, category)
                        
                        if issue_data:
                            issues.append(issue_data)
                            print(f"    âœ… ì´ìŠˆ {i} ì¶”ì¶œ ì™„ë£Œ: {issue_data['ì œëª©'][:30]}...")
                            failed_count = 0  # ì„±ê³µ ì‹œ ì‹¤íŒ¨ ì¹´ìš´íŠ¸ ë¦¬ì…‹
                        else:
                            failed_count += 1
                            print(f"    âš ï¸ ì´ìŠˆ {i} ë°ì´í„° ì—†ìŒ")
                        
                        # íŒì—… ë‹«ê¸° ë° ìœ„ì¹˜ ë³µì›
                        self._close_popup_and_restore()
                        
                        # ì´ìŠˆ ê°„ ëœë¤ ëŒ€ê¸° (íƒì§€ ë°©ì§€)
                        time.sleep(random.uniform(1, 2))
                        
                        # ì—°ì† ì‹¤íŒ¨ê°€ ë§ìœ¼ë©´ ì¡°ê¸° ì¢…ë£Œ
                        if failed_count >= max_failures:
                            print(f"    âš ï¸ ì—°ì† {max_failures}íšŒ ì‹¤íŒ¨ë¡œ ì¡°ê¸° ì¢…ë£Œ")
                            break
                        
                    except Exception as e:
                        failed_count += 1
                        print(f"    âŒ ì´ìŠˆ {i} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                        
                        # ì—°ì† ì‹¤íŒ¨ê°€ ë§ìœ¼ë©´ ì¡°ê¸° ì¢…ë£Œ
                        if failed_count >= max_failures:
                            print(f"    âš ï¸ ì—°ì† {max_failures}íšŒ ì‹¤íŒ¨ë¡œ ì¡°ê¸° ì¢…ë£Œ")
                            break
                        
                        # ì‹¤íŒ¨ ì‹œ ë³µêµ¬ ì‹œë„
                        try:
                            self._recover_from_error()
                        except:
                            pass
                        
                        continue
                
                return issues
            
            def _extract_issue_data_with_retry(self, issue_num: int, category: str, max_retries: int = 3) -> Optional[Dict]:
                """ì´ìŠˆ ë°ì´í„° ì¶”ì¶œ - ì¬ì‹œë„ ë¡œì§ í¬í•¨"""
                for attempt in range(1, max_retries + 1):
                    try:
                        return self._extract_issue_data(issue_num, category)
                    except Exception as e:
                        print(f"    ğŸ”„ ì´ìŠˆ {issue_num} ì¶”ì¶œ ì¬ì‹œë„ {attempt}/{max_retries}: {e}")
                        if attempt < max_retries:
                            time.sleep(2)  # ì¬ì‹œë„ ì „ ëŒ€ê¸°
                        else:
                            print(f"    âŒ ì´ìŠˆ {issue_num} ìµœì¢… ì‹¤íŒ¨")
                            return None
            
            def _recover_from_error(self):
                """ì—ëŸ¬ ë°œìƒ ì‹œ ë³µêµ¬ ì‹œë„"""
                try:
                    # ESC í‚¤ ëˆ„ë¥´ê¸°
                    from selenium.webdriver.common.action_chains import ActionChains
                    from selenium.webdriver.common.keys import Keys
                    ActionChains(self.driver).send_keys(Keys.ESCAPE).perform()
                    time.sleep(1)
                    
                    # ì´ìŠˆ ì„¹ì…˜ìœ¼ë¡œ ë‹¤ì‹œ ìŠ¤í¬ë¡¤
                    self.driver.execute_script("window.scrollTo(0, 880);")
                    time.sleep(2)
                    
                except Exception as e:
                    print(f"    âš ï¸ ì—ëŸ¬ ë³µêµ¬ ì‹¤íŒ¨: {e}")
        
        # í–¥ìƒëœ í¬ë¡¤ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        return EnhancedBigKindsCrawler(
            data_dir=str(self.data_dir),
            headless=self.headless,
            issues_per_category=self.issues_per_category
        )
    
    def _create_failed_result(self, error_msg: str) -> Dict:
        """ì‹¤íŒ¨ ê²°ê³¼ ìƒì„±"""
        return {
            "total_issues": 0,
            "categories": {},
            "crawling_log": [{
                "status": "failed",
                "error": error_msg,
                "timestamp": datetime.now().strftime("%H:%M:%S")
            }],
            "all_issues": [],
            "crawled_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "execution_method": "stable_proxy_with_retry",
            "error": error_msg
        }


class StableCrawlingService:
    """ì•ˆì •ì ì¸ í¬ë¡¤ë§ ì„œë¹„ìŠ¤ (ê¸°ì¡´ CrawlingServiceì™€ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤)"""
    
    def __init__(self, data_dir: str = "data2", headless: bool = True):
        self.data_dir = data_dir
        self.headless = headless
        self.stable_crawler = StableBigKindsCrawler(
            data_dir=data_dir,
            headless=headless
        )
        
        # AI í•„í„°ë§ ì´ˆê¸°í™”
        self._init_ai_filtering()
        
        logger.info("âœ… ì•ˆì •ì ì¸ í¬ë¡¤ë§ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _init_ai_filtering(self):
        """AI í•„í„°ë§ ì´ˆê¸°í™”"""
        try:
            from dotenv import load_dotenv
            from langchain_openai import ChatOpenAI
            
            load_dotenv(override=True)
            self.llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
            logger.info("âœ… OpenAI LLM ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"âš ï¸ OpenAI LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.llm = None
    
    def crawl_and_filter_news(self, 
                             issues_per_category: int = 10,
                             target_filtered_count: int = 5) -> Dict:
        """ì•ˆì •ì ì¸ í¬ë¡¤ë§ + AI í•„í„°ë§"""
        
        logger.info(f"ğŸ•·ï¸ ì•ˆì •ì ì¸ í¬ë¡¤ë§ ì‹œì‘: ì¹´í…Œê³ ë¦¬ë³„ {issues_per_category}ê°œì”©")
        
        # í¬ë¡¤ëŸ¬ ì„¤ì • ì—…ë°ì´íŠ¸
        self.stable_crawler.issues_per_category = issues_per_category
        
        # Step 1: ì•ˆì •ì ì¸ í¬ë¡¤ë§
        crawling_result = self.stable_crawler.crawl_all_categories_with_retry()
        
        # Step 2: AI í•„í„°ë§
        all_issues = crawling_result.get("all_issues", [])
        if all_issues and self.llm:
            filtering_result = self._filter_by_stock_relevance(all_issues, target_filtered_count)
        else:
            filtering_reason = "no_llm" if not self.llm else "no_issues_to_filter"
            filtering_result = {
                "selected_issues": all_issues[:target_filtered_count] if all_issues else [],
                "filter_metadata": {
                    "filtering_method": filtering_reason,
                    "original_count": len(all_issues),
                    "selected_count": min(len(all_issues), target_filtered_count),
                    "filtered_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                }
            }
        
        result = {
            **crawling_result,
            "filtered_issues": filtering_result["selected_issues"],
            "filter_metadata": filtering_result["filter_metadata"],
            "execution_method": "stable_proxy_with_ai_filtering"
        }
        
        logger.info(f"âœ… ì•ˆì •ì ì¸ í¬ë¡¤ë§ ë° í•„í„°ë§ ì™„ë£Œ")
        return result
    
    def _filter_by_stock_relevance(self, all_issues: List[Dict], target_count: int) -> Dict:
        """AI í•„í„°ë§ (ê¸°ì¡´ê³¼ ë™ì¼)"""
        logger.info(f"ğŸ¤– AI í•„í„°ë§ ì‹œì‘: {len(all_issues)}ê°œ â†’ {target_count}ê°œ ì„ ë³„")
        
        if not self.llm:
            return {
                "selected_issues": all_issues[:target_count],
                "filter_metadata": {
                    "filtering_method": "no_ai_simple_slice",
                    "original_count": len(all_issues),
                    "selected_count": min(len(all_issues), target_count),
                    "filtered_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                }
            }
        
        scored_issues = []
        
        for i, issue in enumerate(all_issues, 1):
            try:
                relevance_score = self._analyze_stock_market_relevance(issue)
                scored_issue = issue.copy()
                scored_issue.update({
                    "ì£¼ì‹ì‹œì¥_ê´€ë ¨ì„±_ì ìˆ˜": relevance_score["ì¢…í•©ì ìˆ˜"],
                    "ê´€ë ¨ì„±_ë¶„ì„": relevance_score
                })
                scored_issues.append(scored_issue)
            except Exception as e:
                logger.warning(f"âš ï¸ ì´ìŠˆ {i} AI ë¶„ì„ ì‹¤íŒ¨: {e}")
                scored_issue = issue.copy()
                scored_issue.update({
                    "ì£¼ì‹ì‹œì¥_ê´€ë ¨ì„±_ì ìˆ˜": 5,
                    "ê´€ë ¨ì„±_ë¶„ì„": {"ì¢…í•©ì ìˆ˜": 5, "ë¶„ì„ê·¼ê±°": f"ë¶„ì„ ì‹¤íŒ¨: {e}"}
                })
                scored_issues.append(scored_issue)
        
        scored_issues.sort(key=lambda x: x["ì£¼ì‹ì‹œì¥_ê´€ë ¨ì„±_ì ìˆ˜"], reverse=True)
        selected_issues = scored_issues[:target_count]
        
        for rank, issue in enumerate(selected_issues, 1):
            issue["rank"] = rank
        
        return {
            "selected_issues": selected_issues,
            "filter_metadata": {
                "filtering_method": "stable_gpt-4o-mini_stock_relevance",
                "original_count": len(all_issues),
                "selected_count": len(selected_issues),
                "average_score": sum(issue["ì£¼ì‹ì‹œì¥_ê´€ë ¨ì„±_ì ìˆ˜"] for issue in selected_issues) / len(selected_issues) if selected_issues else 0,
                "filtered_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
        }
    
    def _analyze_stock_market_relevance(self, issue: Dict) -> Dict:
        """AI ì£¼ì‹ì‹œì¥ ê´€ë ¨ì„± ë¶„ì„"""
        from langchain_core.prompts import ChatPromptTemplate
        from langchain_core.output_parsers import JsonOutputParser
        
        if not self.llm:
            raise Exception("LLMì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", "ë‰´ìŠ¤ì˜ ì£¼ì‹ì‹œì¥ ê´€ë ¨ì„±ì„ 1-10ì ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”."),
            ("human", "ì œëª©: {title}\në‚´ìš©: {content}")
        ])
        
        try:
            parser = JsonOutputParser()
            chain = prompt | self.llm | parser
            
            title = issue.get("ì œëª©", issue.get("title", "ì œëª© ì—†ìŒ"))
            content = issue.get("ë‚´ìš©", issue.get("content", "ë‚´ìš© ì—†ìŒ"))
            
            result = chain.invoke({"title": title, "content": content})
            
            return {
                "ì§ì ‘ì _ê¸°ì—…ì˜í–¥": result.get("ì§ì ‘ì _ê¸°ì—…ì˜í–¥", 5),
                "ì‚°ì—…_ì „ë°˜ì˜í–¥": result.get("ì‚°ì—…_ì „ë°˜ì˜í–¥", 5),
                "ê±°ì‹œê²½ì œ_ì˜í–¥": result.get("ê±°ì‹œê²½ì œ_ì˜í–¥", 5),
                "íˆ¬ìì‹¬ë¦¬_ì˜í–¥": result.get("íˆ¬ìì‹¬ë¦¬_ì˜í–¥", 5),
                "ì¢…í•©ì ìˆ˜": result.get("ì¢…í•©ì ìˆ˜", 5),
                "ë¶„ì„ê·¼ê±°": result.get("ë¶„ì„ê·¼ê±°", "AI ë¶„ì„ ì™„ë£Œ")
            }
        except Exception as e:
            raise


# í¸ì˜ í•¨ìˆ˜
def crawl_with_stable_proxy(headless: bool = True, 
                           issues_per_category: int = 10, 
                           target_filtered_count: int = 5) -> Dict:
    """ì•ˆì •ì ì¸ í”„ë¡ì‹œë¡œ í¬ë¡¤ë§"""
    service = StableCrawlingService(headless=headless)
    return service.crawl_and_filter_news(issues_per_category, target_filtered_count)